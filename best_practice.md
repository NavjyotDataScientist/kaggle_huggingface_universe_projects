# üß† Machine Learning Practical Cheat Sheet

This cheat sheet helps you **decide quickly**:
> *‚ÄúIf I see this type of problem ‚Üí which model / concept should I use?‚Äù*

It is designed for **real-world ML work**, Kaggle, GitHub portfolios, and interviews.

---

## 1Ô∏è‚É£ First Question: Do You Have Labels?

| Situation | Choose |
|---------|--------|
| Target variable (y) exists | Supervised Learning |
| No labels | Unsupervised Learning |

---

## 2Ô∏è‚É£ Supervised Learning: Classification vs Regression

| Target Type | Problem Type |
|-----------|-------------|
| Continuous values (price, age) | Regression |
| Categories / classes | Classification |

---

## 3Ô∏è‚É£ Classification Cheat Sheet

### üîπ How many classes?

| Case | Model | Activation |
|----|------|-----------|
| Binary (2 classes) | Logistic Regression | Sigmoid |
| Multiclass (1 of many) | Logistic Regression | Softmax |
| Multilabel (many per row) | OneVsRestClassifier | Sigmoid |

### üß† Memory Trick
- **Sigmoid** ‚Üí single ON/OFF switch  
- **Softmax** ‚Üí competition between classes  
- **One-vs-Rest** ‚Üí multiple binary decisions  

---

## 4Ô∏è‚É£ Which Classification Model to Start With?

| Situation | Start With |
|--------|-----------|
| Small dataset | Logistic Regression |
| Text data | Naive Bayes |
| Complex boundary | SVM |
| Overfitting | Random Forest |
| High accuracy needed | Gradient Boosting |

---

## 5Ô∏è‚É£ Regression Cheat Sheet

### üîπ Shape of relationship?

| Pattern | Model |
|------|------|
| Straight line | Linear Regression |
| Multiple inputs | Multiple Linear Regression |
| Curve | Polynomial Regression |

---

## 6Ô∏è‚É£ Regularization (When Model Misbehaves)

| Problem | Solution |
|------|---------|
| Overfitting | Ridge Regression |
| Too many features | Lasso Regression |
| Both issues | Elastic Net |

### üß† Memory Trick
- **Ridge** shrinks weights  
- **Lasso** removes features  
- **Elastic Net** balances both  

---

## 7Ô∏è‚É£ Tree-Based Models

| Scenario | Model |
|--------|------|
| Simple rules | Decision Tree |
| Overfitting trees | Random Forest |
| Best performance | Gradient Boosting |

---

## 8Ô∏è‚É£ Distance-Based Models

| Situation | Use |
|--------|----|
| Similarity matters | KNN |
| Small dataset | KNN |
| Large dataset | ‚ùå Avoid KNN |

---

## 9Ô∏è‚É£ Loss Functions

| Task | Loss Function |
|----|--------------|
| Regression | MSE / MAE |
| Classification | Log Loss |
| Probability models | Cross-Entropy |

---

## üîü Evaluation Metrics

| Problem | Metric |
|------|------|
| Balanced classification | Accuracy |
| Imbalanced classification | Precision / Recall |
| Regression | RMSE, R¬≤ |

---

## 11Ô∏è‚É£ IF YOU SEE ‚Üí DO THIS (FAST DECISION TABLE)

| You See | You Do |
|------|-------|
| Binary labels | Sigmoid |
| Multiple classes | Softmax |
| Multiple labels | OneVsRest |
| Curved data | Polynomial |
| Noise | Regularization |
| Overfitting | Random Forest |
| Text data | Naive Bayes |
| Need fast baseline | Logistic Regression |

---

## üìÇ Recommended Project Structure

